import os
import pandas as pd
import requests
import zipfile
import io
import json
from datetime import datetime
from typing import List, Dict, Any

# --- 1. ××•×“×•×œ Setup ×•×§×¨×™××ª × ×ª×•× ×™× ---

GTFS_URL = "https://gtfs.mot.gov.il/gtfsfiles/israel-public-transportation.zip"
OUTPUT_FILENAME = "harish_multi_route_schedule.json"

# ×§×¨×™××ª × ×ª×•× ×™× ×××©×ª× ×™ ×¡×‘×™×‘×” ××• ×©×™××•×© ×‘×¢×¨×›×™ ×‘×¨×™×¨×ª ××—×“×œ
# Note: ××©×ª× ×™ ×¡×‘×™×‘×” ×™×•×’×“×¨×• ×‘×§×•×‘×¥ main.yml
TARGET_ROUTES_STR = os.environ.get('TARGET_ROUTES', "20,20×,22,60,60×,71,71×,632,634,942,160,163,63")
TARGET_STOPS_STR = os.environ.get('TARGET_STOPS', "43898,43899,43897,43334,43496,40662")

TARGET_ROUTES: List[str] = [r.strip() for r in TARGET_ROUTES_STR.split(',')]
TARGET_STOPS: List[int] = [int(s.strip()) for s in TARGET_STOPS_STR.split(',')]

def download_and_extract_gtfs(url: str) -> zipfile.ZipFile:
    """××•×¨×™×“ ××ª ×§×•×‘×¥ ×”-ZIP ×•××—×œ×¥ ××•×ª×• ×œ×–×™×›×¨×•×Ÿ (×¢× ×¢×§×™×¤×ª SSL)"""
    print(f"[SETUP] 1. ××•×¨×™×“ ×§×•×‘×¥ GTFS ×: {url}")
    # ×©×™××•×© ×‘-verify=False ×›×“×™ ×œ×¢×§×•×£ ×©×’×™××•×ª SSL ×‘-GitHub Actions
    response = requests.get(url, stream=True, verify=False)
    response.raise_for_status() 
    
    zip_in_memory = io.BytesIO(response.content)
    return zipfile.ZipFile(zip_in_memory)

def load_gtfs_files(zf: zipfile.ZipFile) -> Dict[str, pd.DataFrame]:
    """×˜×•×¢×Ÿ ××ª ×§×‘×¦×™ ×”-GTFS ×”×¨×œ×•×•× ×˜×™×™× ×œ-Pandas DataFrames"""
    print("[SETUP] 2. ×˜×•×¢×Ÿ ×§×‘×¦×™ GTFS...")
    return {
        'routes': pd.read_csv(zf.open('routes.txt'), dtype={'route_short_name': str}),
        'stops': pd.read_csv(zf.open('stops.txt')),
        'trips': pd.read_csv(zf.open('trips.txt')),
        'stop_times': pd.read_csv(zf.open('stop_times.txt')),
        'calendar': pd.read_csv(zf.open('calendar.txt'))
    }

# --- 2. ××•×“×•×œ Core Logic ---

def get_today_service_ids(calendar: pd.DataFrame) -> List[str]:
    """××•×¦× ××ª ××–×”×™ ×”×©×™×¨×•×ª (Service IDs) ×©×¤×¢×™×œ×™× ×”×™×•×"""
    
    # 1. ××¦×™××ª ×©× ×”×™×•× ×‘×× ×’×œ×™×ª (×œ×“×•×’××”: friday)
    today_weekday = datetime.now().strftime('%A').lower() 
    
    # 2. ××™×¤×•×™ ×©× ×”×™×•× ×œ×©× ×”×©×“×” ×‘-GTFS (×‘××§×¨×” ×–×”, ×–×” ×–×”×”)
    day_mapping = {
        'monday': 'monday', 'tuesday': 'tuesday', 'wednesday': 'wednesday',
        'thursday': 'thursday', 'friday': 'friday', 'saturday': 'saturday', 'sunday': 'sunday'
    }
    
    day_column = day_mapping.get(today_weekday, None)
    
    if day_column is None or day_column not in calendar.columns:
        print(f"[CORE] ×©×’×™××”: ×œ× × ×™×ª×Ÿ ×œ××¤×•×ª ××ª ×”×™×•× '{today_weekday}' ×œ×¢××•×“×ª ×”-GTFS.")
        return []
    
    print(f"[CORE] ××¡× ×Ÿ Service IDs ×¢×‘×•×¨ ×”×™×•×: {day_column}")
    
    # ×¡×™× ×•×Ÿ ×œ×¤×™ ×™×•× ×‘×©×‘×•×¢ (×©×•×•×™×•×Ÿ ×œ-1)
    calendar_today = calendar[calendar[day_column] == 1]
    
    return calendar_today['service_id'].unique().tolist()



def find_departure_schedules(gtfs_data: Dict[str, pd.DataFrame], service_ids: List[str]) -> List[Dict[str, Any]]:
    """××•×¦× ××ª ×–×× ×™ ×”×™×¦×™××” ××ª×—× ×•×ª ×”×™×¢×“ ×¢×‘×•×¨ ×”×§×•×•×™× ×”×¤×¢×™×œ×™× ×”×™×•×"""
    
    routes = gtfs_data['routes']
    trips = gtfs_data['trips']
    stop_times = gtfs_data['stop_times']
    stops = gtfs_data['stops']
    
    # 2.1. ×¡×™× ×•×Ÿ × ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×•×¨×œ×•×•× ×˜×™×•×ª
    print(f"[CORE] 3. ××¡× ×Ÿ ×§×•×•×™× ×¨×œ×•×•× ×˜×™×™× ({len(TARGET_ROUTES)} ×§×•×•×™×)...")
    target_routes_df = routes[routes['route_short_name'].isin(TARGET_ROUTES)]
    target_route_ids = target_routes_df['route_id'].unique().tolist()
    
    # ×¡×™× ×•×Ÿ × ×¡×™×¢×•×ª (Trips) ×©×œ ×”×§×•×•×™× ×”× ×‘×—×¨×™×, ×©×¤×¢×™×œ×•×ª ×”×™×•×
    target_trips = trips[
        (trips['route_id'].isin(target_route_ids)) &
        (trips['service_id'].isin(service_ids))
    ].copy()
    
    if target_trips.empty:
        print("[CORE]   **××–×”×¨×”:** ×œ× × ××¦××• × ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×”×™×•× ×¢×‘×•×¨ ×”×§×•×•×™× ×”××‘×•×§×©×™×.")
        return []

    # 2.2. ××¦×™××ª ×–×× ×™ ×™×¦×™××” ×‘×ª×—× ×•×ª ×”×™×¢×“
    print(f"[CORE] 4. ××•×¦× ×–×× ×™ ×™×¦×™××” ××ª×—× ×•×ª ×”×™×¢×“...")
    
    # *** ×”×ª×™×§×•×Ÿ ×”×¢×™×§×¨×™: ××™×–×•×’ ×™×©×™×¨ ×‘×™×Ÿ ×”× ×¡×™×¢×•×ª ×”×¤×¢×™×œ×•×ª ×œ×–×× ×™ ×”×¢×¦×™×¨×” ×‘×ª×—× ×•×ª ×”×™×¢×“ ***
    
    # ×›×œ ×–×× ×™ ×”×¢×¦×™×¨×” ×‘×ª×—× ×•×ª ×”×™×¢×“ ×©×œ×š
    relevant_stop_times = stop_times[
        stop_times['stop_id'].isin(TARGET_STOPS) 
    ].copy()
    
    # ×—×™×ª×•×š (AND) ×‘×™×Ÿ ×”× ×¡×™×¢×•×ª ×”×¤×¢×™×œ×•×ª ×œ×–×× ×™ ×”×¢×¦×™×¨×” ×‘×ª×—× ×•×ª ×”×™×¢×“
    final_relevant_stop_times = relevant_stop_times[
        relevant_stop_times['trip_id'].isin(target_trips['trip_id'])
    ].copy()
    
    if final_relevant_stop_times.empty:
        # ×”×•×“×¢×” ×–×• ×”×™× ×”××“×•×™×§×ª ×‘×™×•×ª×¨ ×œ××¦×‘ ×”× ×•×›×—×™:
        print("[CORE]   **××–×”×¨×”:** ××£ × ×¡×™×¢×” ×¤×¢×™×œ×” ×”×™×•× (×™×•× ×©×™×©×™) ××™× ×” ×¢×•×¦×¨×ª ×‘×ª×—× ×•×ª ×”×™×¢×“ ×©×¦×•×™× ×•.")
        return []
    
    # 2.3. ××™×—×•×“ ×”× ×ª×•× ×™× ×•×¡×™× ×•×Ÿ ×›×¤×™×œ×•×™×•×ª
    
    # ××™×–×•×’ ×¢× ×¤×¨×˜×™ ×”× ×¡×™×¢×” ×•×”×§×•
    merged_data = pd.merge(final_relevant_stop_times, target_trips, on='trip_id')
    merged_data = pd.merge(merged_data, routes[['route_id', 'route_short_name']], on='route_id')
    merged_data = pd.merge(merged_data, stops[['stop_id', 'stop_name']], on='stop_id', how='left')

    # ×¡×™× ×•×Ÿ ×›×¤×™×œ×•×™×•×ª: ×× ××•×ª×• ×§×• ×™×•×¦× ×‘××•×ª×” ×©×¢×” ×××•×ª×” ×ª×—× ×”
    unique_departures = merged_data.drop_duplicates(
        subset=['route_short_name', 'departure_time', 'stop_id'], 
        keep='first'
    )
    
    # 2.4. ×™×¦×™×¨×ª ×”×¤×œ×˜ ×”×¡×•×¤×™
    print(f"[CORE] 5. × ××¦××• {len(unique_departures)} ×™×¦×™××•×ª ×™×™×—×•×“×™×•×ª.")
    
    # ×¡×™×“×•×¨ ×”× ×ª×•× ×™×
    unique_departures = unique_departures[[
        'route_short_name', 
        'departure_time', 
        'stop_name', 
        'direction_id',
        'stop_sequence'
    ]].sort_values(by=['route_short_name', 'departure_time'])
    
    return unique_departures.to_dict('records')


# --- 3. ××•×“×•×œ Output ×•×¤×•× ×§×¦×™×” ×¨××©×™×ª ---

def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª ×©×× ×”×œ×ª ××ª ×”×ª×”×œ×™×š ×›×•×œ×•"""
    # ×”×“×¤×¡×ª ×”×¤×¨××˜×¨×™× ×©× ×‘×—×¨×•
    print("-" * 50)
    print(f"[MAIN] ×§×•×•×™× × ×‘×—×¨×™×: {TARGET_ROUTES}")
    print(f"[MAIN] ×ª×—× ×•×ª ×™×¢×“ (IDs): {TARGET_STOPS}")
    print("-" * 50)

    try:
        # 1. ×˜×¢×™× ×ª × ×ª×•× ×™×
        zip_file_obj = download_and_extract_gtfs(GTFS_URL)
        gtfs_data = load_gtfs_files(zip_file_obj)
        
        # *** DEBUG: ×”×“×¤×¡×ª ×©××•×ª ×”×ª×—× ×•×ª ×©× ×˜×¢× ×• ***
        stops_df = gtfs_data['stops']
        found_stops = stops_df[stops_df['stop_id'].isin(TARGET_STOPS)]
        
        if found_stops.empty:
             raise ValueError("××£ ××—×“ ×-Stop ID ×©×”×•×–× ×• ×œ× × ××¦× ×‘×§×•×‘×¥ stops.txt. ×•×“× ×©×”-IDs × ×›×•× ×™×.")
             
        print(f"[DEBUG] ×©××•×ª ×”×ª×—× ×•×ª ×©× ×˜×¢× ×•: {found_stops['stop_name'].unique().tolist()}")
        # *****************************************
        
        # 2. ×¢×™×‘×•×“ ×œ×•×’×™ - ×‘×™×˜×•×œ ×¡×™× ×•×Ÿ ×™×•× ×œ×—×œ×•×˜×™×Ÿ (×›×“×™ ×œ××¦×•× ××ª ×›×œ ×”×ª×•×¦××•×ª ×”××¤×©×¨×™×•×ª)
        service_ids = gtfs_data['calendar']['service_id'].unique().tolist()
        print(f"[CORE] × ××¦××• {len(service_ids)} ALL Service IDs (DEBUG MODE - ALL DAYS).")
        
        schedule_data = find_departure_schedules(gtfs_data, service_ids)

        # 3. ×©××™×¨×ª ×”×¤×œ×˜
        print(f"[OUTPUT] ×©×•××¨ {len(schedule_data)} ×¨×©×•××•×ª ×œ×§×•×‘×¥ {OUTPUT_FILENAME}...")
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            # ×”×•×¡×¤×ª ×›×•×ª×¨×ª ×œ-JSON
            final_output = {
                "update_time": datetime.now().isoformat(),
                "query_routes": TARGET_ROUTES,
                "query_stops": TARGET_STOPS,
                "results": schedule_data
            }
            json.dump(final_output, f, ensure_ascii=False, indent=4)
        
        print(f"[MAIN] ğŸŒŸ ×¡×™×•× ××•×¦×œ×—! × ×ª×•× ×™× × ×©××¨×• ×‘×”×¦×œ×—×”.")
        
    except Exception as e:
        print(f"[MAIN] âŒ ×©×’×™××” ×§×¨×™×˜×™×ª: {e}")
        # ×©××™×¨×ª ×§×•×‘×¥ ×©×’×™××” ×’× ×‘××§×¨×” ×©×œ ×›×©×œ
        error_output = {
            "update_time": datetime.now().isoformat(),
            "error": str(e),
            "note": "Processing failed. Check GitHub Actions log for full traceback."
        }
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(error_output, f, ensure_ascii=False, indent=4)
        exit(1)

if __name__ == "__main__":
    # ×”×©×ª×§×ª ××–×”×¨×•×ª SSL ×× ×§×™×™××•×ª (×¨×œ×•×•× ×˜×™ ×œ×¡×‘×™×‘×ª ×œ×™× ×•×§×¡)
    try:
        import urllib3 
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    except:
        pass # ×”×ª×¢×œ××•×ª ×× ×”×¡×¤×¨×™×™×” ×œ× ×§×™×™××ª
        
    main()