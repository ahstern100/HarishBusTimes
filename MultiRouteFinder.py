import os
import pandas as pd
import requests
import zipfile
import io
import json
from datetime import datetime
from typing import List, Dict, Any

# --- 1. ××•×“×•×œ Setup ×•×§×¨×™××ª × ×ª×•× ×™× ---

GTFS_URL = "https://gtfs.mot.gov.il/gtfsfiles/israel-public-transportation.zip"
OUTPUT_FILENAME = "harish_multi_route_schedule.json"

# ×§×¨×™××ª × ×ª×•× ×™× ×××©×ª× ×™ ×¡×‘×™×‘×” ××• ×©×™××•×© ×‘×¢×¨×›×™ ×‘×¨×™×¨×ª ××—×“×œ
# Note: ××©×ª× ×™ ×¡×‘×™×‘×” ×™×•×’×“×¨×• ×‘×§×•×‘×¥ main.yml
TARGET_ROUTES_STR = os.environ.get('TARGET_ROUTES', "20,20×,22,60,60×,71,71×,632,634,942,160,163,63")
TARGET_STOPS_STR = os.environ.get('TARGET_STOPS', "43898,43899,43897,43334,43496,40662")

TARGET_ROUTES: List[str] = [r.strip() for r in TARGET_ROUTES_STR.split(',')]
TARGET_STOPS: List[int] = [int(s.strip()) for s in TARGET_STOPS_STR.split(',')]

def download_and_extract_gtfs(url: str) -> zipfile.ZipFile:
    """××•×¨×™×“ ××ª ×§×•×‘×¥ ×”-ZIP ×•××—×œ×¥ ××•×ª×• ×œ×–×™×›×¨×•×Ÿ (×¢× ×¢×§×™×¤×ª SSL)"""
    print(f"[SETUP] 1. ××•×¨×™×“ ×§×•×‘×¥ GTFS ×: {url}")
    # ×©×™××•×© ×‘-verify=False ×›×“×™ ×œ×¢×§×•×£ ×©×’×™××•×ª SSL ×‘-GitHub Actions
    response = requests.get(url, stream=True, verify=False)
    response.raise_for_status() 
    
    zip_in_memory = io.BytesIO(response.content)
    return zipfile.ZipFile(zip_in_memory)

def load_gtfs_files(zf: zipfile.ZipFile) -> Dict[str, pd.DataFrame]:
    """×˜×•×¢×Ÿ ××ª ×§×‘×¦×™ ×”-GTFS ×”×¨×œ×•×•× ×˜×™×™× ×œ-Pandas DataFrames"""
    print("[SETUP] 2. ×˜×•×¢×Ÿ ×§×‘×¦×™ GTFS...")
    return {
        'routes': pd.read_csv(zf.open('routes.txt'), dtype={'route_short_name': str}),
        'stops': pd.read_csv(zf.open('stops.txt')),
        'trips': pd.read_csv(zf.open('trips.txt')),
        'stop_times': pd.read_csv(zf.open('stop_times.txt')),
        'calendar': pd.read_csv(zf.open('calendar.txt'))
    }

# --- 2. ××•×“×•×œ Core Logic ---

def get_today_service_ids(calendar: pd.DataFrame) -> List[str]:
    """××•×¦× ××ª ××–×”×™ ×”×©×™×¨×•×ª (Service IDs) ×©×¤×¢×™×œ×™× ×”×™×•×"""
    
    # 1. ××¦×™××ª ×©× ×”×™×•× ×‘×× ×’×œ×™×ª (×œ×“×•×’××”: friday)
    today_weekday = datetime.now().strftime('%A').lower() 
    
    # 2. ××™×¤×•×™ ×©× ×”×™×•× ×œ×©× ×”×©×“×” ×‘-GTFS (×‘××§×¨×” ×–×”, ×–×” ×–×”×”)
    day_mapping = {
        'monday': 'monday', 'tuesday': 'tuesday', 'wednesday': 'wednesday',
        'thursday': 'thursday', 'friday': 'friday', 'saturday': 'saturday', 'sunday': 'sunday'
    }
    
    day_column = day_mapping.get(today_weekday, None)
    
    if day_column is None or day_column not in calendar.columns:
        print(f"[CORE] ×©×’×™××”: ×œ× × ×™×ª×Ÿ ×œ××¤×•×ª ××ª ×”×™×•× '{today_weekday}' ×œ×¢××•×“×ª ×”-GTFS.")
        return []
    
    print(f"[CORE] ××¡× ×Ÿ Service IDs ×¢×‘×•×¨ ×”×™×•×: {day_column}")
    
    # ×¡×™× ×•×Ÿ ×œ×¤×™ ×™×•× ×‘×©×‘×•×¢ (×©×•×•×™×•×Ÿ ×œ-1)
    calendar_today = calendar[calendar[day_column] == 1]
    
    return calendar_today['service_id'].unique().tolist()

def find_departure_schedules(gtfs_data: Dict[str, pd.DataFrame], service_ids: List[str]) -> List[Dict[str, Any]]:
    """××•×¦× ××ª ×œ×•×—×•×ª ×”×–×× ×™× ×”××‘×•×§×©×™× ×•××–×”×” ×ª×—× ×•×ª ××•×¦×"""
    
    routes = gtfs_data['routes']
    trips = gtfs_data['trips']
    stop_times = gtfs_data['stop_times']
    stops = gtfs_data['stops']
    
    final_results = []
    

    # 2.1. ×¡×™× ×•×Ÿ × ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×•×¨×œ×•×•× ×˜×™×•×ª
    print(f"[CORE] 3. ××¡× ×Ÿ ×§×•×•×™× ×¨×œ×•×•× ×˜×™×™× ({len(TARGET_ROUTES)} ×§×•×•×™×)...")
    target_routes_df = routes[routes['route_short_name'].isin(TARGET_ROUTES)]
    target_route_ids = target_routes_df['route_id'].unique().tolist()
    
    # ×›×œ ×”× ×¡×™×¢×•×ª (Trip IDs) ×©×œ ×”×§×•×•×™× ×”××œ×” ×©×¤×¢×™×œ×•×ª ×”×™×•×
    target_trips = trips[
        (trips['route_id'].isin(target_route_ids)) &
        (trips['service_id'].isin(service_ids))
    ].copy()
    
    # *** DEBUG 1: ×›××” × ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×”×™×•×? ***
    print(f"[DEBUG 1] × ××¦××• {len(target_trips)} × ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×”×™×•× ×‘×§×•×•×™× ×”× ×‘×—×¨×™×.")
    # *****************************************
    
    if target_trips.empty:
        print("[CORE]   **××–×”×¨×”:** ×œ× × ××¦××• × ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×”×™×•× ×¢×‘×•×¨ ×”×§×•×•×™× ×”××‘×•×§×©×™×.")
        return []

    # 2.2. ×–×™×”×•×™ × ×¡×™×¢×•×ª ×©×¢×•×‘×¨×•×ª ×‘×ª×—× ×•×ª ×”×™×¢×“
    # ××™×–×•×’ ×¢× stop_times ×›×“×™ ×œ×“×¢×ª ××™×œ×• × ×¡×™×¢×•×ª ×¢×•×‘×¨×•×ª ×‘×ª×—× ×•×ª ×©×œ× ×•
    relevant_stop_times = stop_times[
        stop_times['stop_id'].isin(TARGET_STOPS)
    ].copy()
    
    relevant_trip_ids = relevant_stop_times['trip_id'].unique()
    
    # *** DEBUG 2: ×›××” × ×¡×™×¢×•×ª ×¢×•×‘×¨×•×ª ×‘×ª×—× ×•×ª ×”×™×¢×“ ×©×œ×š (×›×œ ×™×•×)? ***
    print(f"[DEBUG 2] × ××¦××• {len(relevant_trip_ids)} × ×¡×™×¢×•×ª ×©×¢×•×‘×¨×•×ª ×‘×ª×—× ×•×ª ×”×™×¢×“ (×‘×›×œ ×™×•×).")
    # *****************************************
    
    # ×¡×™× ×•×Ÿ ×”-Trips ×©×’× ×¨×œ×•×•× ×˜×™×™× (×”×™×•×) ×•×’× ×¢×•×‘×¨×™× ×‘×ª×—× ×•×ª ×©×œ× ×•
    final_relevant_trips = target_trips[
        target_trips['trip_id'].isin(relevant_trip_ids)
    ].copy()
    
    # *** DEBUG 3: ×’×•×“×œ ×”×—×™×ª×•×š ×”×¡×•×¤×™ ***
    print(f"[DEBUG 3] ×’×•×“×œ ×”×—×™×ª×•×š ×”×¡×•×¤×™ (× ×¡×™×¢×•×ª ×¤×¢×™×œ×•×ª ×©×¢×•×‘×¨×•×ª ×‘×ª×—× ×•×ª) ×”×•×: {len(final_relevant_trips)}")
    # **********************************
    
    if final_relevant_trips.empty:
        print("[CORE]   **××–×”×¨×”:** ×”×—×™×ª×•×š ×¨×™×§. ××™×Ÿ ×—×¤×™×¤×” ×‘×™×Ÿ ×”×§×•×•×™× ×”×¤×¢×™×œ×™× ×œ×ª×—× ×•×ª ×”×™×¢×“.")
        return []


    # 2.3. ××¦×™××ª ×ª×—× ×ª ×”××•×¦× ×©×œ ×›×œ × ×¡×™×¢×” ×©× ××¦××”
    print(f"[CORE] 4. ××•×¦× ×ª×—× ×•×ª ××•×¦× ×¢×‘×•×¨ {len(final_relevant_trips)} × ×¡×™×¢×•×ª ×¨×œ×•×•× ×˜×™×•×ª...")
    
    # ××•×¦××™× ××ª ×ª×—× ×ª ×”××•×¦× (stop_sequence = 1) ×©×œ ×›×œ × ×¡×™×¢×”
    origin_stop_times = stop_times[
        (stop_times['trip_id'].isin(final_relevant_trips['trip_id'])) &
        (stop_times['stop_sequence'] == 1)
    ].copy()
    
    # 2.4. ××™×—×•×“ ×”× ×ª×•× ×™× ×•×¡×™× ×•×Ÿ ×›×¤×™×œ×•×™×•×ª
    
    # ××™×–×•×’ ×¢× ×¤×¨×˜×™ ×”× ×¡×™×¢×” ×•×”×§×•
    merged_data = pd.merge(origin_stop_times, final_relevant_trips, on='trip_id')
    merged_data = pd.merge(merged_data, routes[['route_id', 'route_short_name']], on='route_id')
    merged_data = pd.merge(merged_data, stops[['stop_id', 'stop_name']], on='stop_id', how='left')

    # ×¡×™× ×•×Ÿ ×›×¤×™×œ×•×™×•×ª: ×× ××•×ª×• ×§×• (route_short_name) ×™×•×¦× ×‘××•×ª×” ×©×¢×” (departure_time)
    # ×××•×ª×” ×ª×—× ×”, ×–×• ×›×¤×™×œ×•×ª ×©× ×•×¦×¨×” ×××™×–×•×’ ×”× ×ª×•× ×™×, ××– × ×©××•×¨ ×¨×§ ××ª ×”×™×™×—×•×“×™×™×.
    unique_departures = merged_data.drop_duplicates(
        subset=['route_short_name', 'departure_time', 'stop_id'], 
        keep='first'
    )
    
    # 2.5. ×™×¦×™×¨×ª ×”×¤×œ×˜ ×”×¡×•×¤×™
    print(f"[CORE] 5. × ××¦××• {len(unique_departures)} ×™×¦×™××•×ª ×™×™×—×•×“×™×•×ª.")
    
    # ×¡×™×“×•×¨ ×”× ×ª×•× ×™×
    unique_departures = unique_departures[[
        'route_short_name', 
        'departure_time', 
        'stop_name', 
        'trip_id', 
        'direction_id'
    ]].sort_values(by=['route_short_name', 'departure_time'])
    
    return unique_departures.to_dict('records')


# --- 3. ××•×“×•×œ Output ×•×¤×•× ×§×¦×™×” ×¨××©×™×ª ---

def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª ×©×× ×”×œ×ª ××ª ×”×ª×”×œ×™×š ×›×•×œ×•"""
    # ×”×“×¤×¡×ª ×”×¤×¨××˜×¨×™× ×©× ×‘×—×¨×•
    print("-" * 50)
    print(f"[MAIN] ×§×•×•×™× × ×‘×—×¨×™×: {TARGET_ROUTES}")
    print(f"[MAIN] ×ª×—× ×•×ª ×™×¢×“ (IDs): {TARGET_STOPS}")
    print("-" * 50)

    try:
        # 1. ×˜×¢×™× ×ª × ×ª×•× ×™×
        zip_file_obj = download_and_extract_gtfs(GTFS_URL)
        gtfs_data = load_gtfs_files(zip_file_obj)
        
        # 2. ×¢×™×‘×•×“ ×œ×•×’×™
        service_ids = get_today_service_ids(gtfs_data['calendar'])
        print(f"[CORE] × ××¦××• {len(service_ids)} Service IDs ×¤×¢×™×œ×™× ×”×™×•×.")
        
        schedule_data = find_departure_schedules(gtfs_data, service_ids)
        
        # 3. ×©××™×¨×ª ×”×¤×œ×˜
        print(f"[OUTPUT] ×©×•××¨ {len(schedule_data)} ×¨×©×•××•×ª ×œ×§×•×‘×¥ {OUTPUT_FILENAME}...")
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            # ×”×•×¡×¤×ª ×›×•×ª×¨×ª ×œ-JSON
            final_output = {
                "update_time": datetime.now().isoformat(),
                "query_routes": TARGET_ROUTES,
                "query_stops": TARGET_STOPS,
                "results": schedule_data
            }
            json.dump(final_output, f, ensure_ascii=False, indent=4)
        
        print(f"[MAIN] ğŸŒŸ ×¡×™×•× ××•×¦×œ×—! × ×ª×•× ×™× × ×©××¨×• ×‘×”×¦×œ×—×”.")
        
    except Exception as e:
        print(f"[MAIN] âŒ ×©×’×™××” ×§×¨×™×˜×™×ª: {e}")
        # ×©××™×¨×ª ×§×•×‘×¥ ×©×’×™××” ×’× ×‘××§×¨×” ×©×œ ×›×©×œ
        error_output = {
            "update_time": datetime.now().isoformat(),
            "error": str(e),
            "note": "Processing failed. Check GitHub Actions log for full traceback."
        }
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(error_output, f, ensure_ascii=False, indent=4)
        exit(1)

if __name__ == "__main__":
    # ×”×©×ª×§×ª ××–×”×¨×•×ª SSL ×× ×§×™×™××•×ª (×¨×œ×•×•× ×˜×™ ×œ×¡×‘×™×‘×ª ×œ×™× ×•×§×¡)
    try:
        import urllib3 
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    except:
        pass # ×”×ª×¢×œ××•×ª ×× ×”×¡×¤×¨×™×™×” ×œ× ×§×™×™××ª
        
    main()